{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6126a6c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "   <center>\n",
    "       <h3>Time Series Multi-Horizon Forecasting : comment prédire des phénomènes non stationnaires à des horizons de temps multiples ?</h3>\n",
    "       <br>\n",
    "      <p>Bonjour et bienvenu à cet atelier datacraft en collaboration avec Danone.</p>\n",
    "</center>\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0b343",
   "metadata": {},
   "source": [
    "L'objectif de cet atelier est de prédire la colonne ``ordered_volumes`` du jeu de données à différents horizons (1 semaines, 3 mois, 1 an). \n",
    "\n",
    "Il y a au total 125 produits différents mais vous pouvez vous concentrer sur seulement un produit de chaque cluster déterminé par Gabriel. Cette partie est détaillée dans le notebook **Clustering datacraft**\n",
    "\n",
    "Nous pouvons donc nous concentrer sur un ou deux produit par cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854bbe2",
   "metadata": {},
   "source": [
    "Ce notebook est dédié à l'exploration des données Danone et à l'utilisation des packages **prophet** et **neural prophet**.\n",
    "\n",
    "La fonction ``train_prophet_model`` permet d'entrainer un model prophet tout en modulant les paramètre en se passant de l'API prophet d'origine.\n",
    "\n",
    "La documentation et les exemples permettent de bien comprendre son utilisation mais n'hésitez pas à nous poser la moindre question.\n",
    "\n",
    "Si vous voulez vous passer de la fonction et passer directement par l'API (notamment si vous voulez faire de la cross validation, ajouter des saisonnalités ou moduler des paramètres non présents dans la fonction) je vous invite à regarder la doc prophet : \n",
    "\n",
    "- https://facebook.github.io/prophet/docs/quick_start.html#python-api\n",
    "- https://github.com/facebook/prophet/blob/main/python/prophet/forecaster.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205fc909",
   "metadata": {},
   "source": [
    "# Charger les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969108cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\amiar\\AppData\\Local\\Temp\\ipykernel_9548\\4127398410.py:28: UserWarning:\n",
      "\n",
      "\n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import prophet\n",
    "import numpy as np\n",
    "from dash import Dash, State\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from prophet import Prophet \n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from neuralprophet import NeuralProphet \n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.tools import mpl_to_plotly\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Output, Input\n",
    "\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc6728",
   "metadata": {},
   "source": [
    "# Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad67b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/forecasting.parquet.gzip\")\n",
    "danone = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cef404e",
   "metadata": {},
   "source": [
    "# Dictionnaire de sélection de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0763d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Colonnes qui vont rester dans le dataframe ou non, 0 si non, 1 si oui, \n",
    "si le nom n'est pas dedans, alors la colonne ne reste pas'''\n",
    "\n",
    "selected_columns = {\"time_index\" : 1,\"apparenttemperaturemax\" :1,\"cos_iso_month\" : 0,\"cos_iso_week\" : 0,\"cos_iso_week_of_month\": 0,\"days_before_next_holiday\": 0,\"forecasted_volumes\": 0,\"fu_cod\": 0,\"future_ordered_volumes_until_saturday_of_current_week\": 0,\"future_ordered_volumes_until_saturday_of_previous_week\": 0,\"holiday_day_of_week\": 0,\"holidays_count_in_week\": 0,\"iso_month\": 0,\"iso_week\": 0,\"iso_week_of_month\": 0,\"mat_net_weight_value_kg\": 0,\"ordered_volumes\": 1,\"precipintensity\": 1,\"promo_uplift_coefficient\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe62a5",
   "metadata": {},
   "source": [
    "# Présentation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a468ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_index</th>\n",
       "      <th>product_index</th>\n",
       "      <th>ordered_volumes</th>\n",
       "      <th>future_ordered_volumes_until_saturday_of_current_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26946</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>60198</td>\n",
       "      <td>136.199997</td>\n",
       "      <td>136.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26947</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>60198</td>\n",
       "      <td>142.199997</td>\n",
       "      <td>142.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26948</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>60198</td>\n",
       "      <td>162.600006</td>\n",
       "      <td>162.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26949</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>60198</td>\n",
       "      <td>181.199997</td>\n",
       "      <td>181.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26950</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>60198</td>\n",
       "      <td>184.199997</td>\n",
       "      <td>184.199997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_index  product_index  ordered_volumes  \\\n",
       "26946 2017-01-09          60198       136.199997   \n",
       "26947 2017-01-16          60198       142.199997   \n",
       "26948 2017-01-23          60198       162.600006   \n",
       "26949 2017-01-30          60198       181.199997   \n",
       "26950 2017-02-06          60198       184.199997   \n",
       "\n",
       "       future_ordered_volumes_until_saturday_of_current_week  \n",
       "26946                                         136.199997      \n",
       "26947                                         142.199997      \n",
       "26948                                         162.600006      \n",
       "26949                                         181.199997      \n",
       "26950                                         184.199997      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values([\"product_index\", \"time_index\"])\\\n",
    "    .head()[[\"time_index\",\"product_index\",\"ordered_volumes\", \"future_ordered_volumes_until_saturday_of_current_week\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72afa58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_index</th>\n",
       "      <th>product_index</th>\n",
       "      <th>ordered_volumes</th>\n",
       "      <th>promo_mean_horizon_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26946</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>60198</td>\n",
       "      <td>136.199997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26947</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>60198</td>\n",
       "      <td>142.199997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26948</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>60198</td>\n",
       "      <td>162.600006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26949</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>60198</td>\n",
       "      <td>181.199997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26950</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>60198</td>\n",
       "      <td>184.199997</td>\n",
       "      <td>10.653943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_index  product_index  ordered_volumes  promo_mean_horizon_0\n",
       "26946 2017-01-09          60198       136.199997              0.000000\n",
       "26947 2017-01-16          60198       142.199997              0.000000\n",
       "26948 2017-01-23          60198       162.600006              0.000000\n",
       "26949 2017-01-30          60198       181.199997              0.000000\n",
       "26950 2017-02-06          60198       184.199997             10.653943"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values([\"product_index\",\"time_index\"])\\\n",
    "    .head()[[\"time_index\",\"product_index\",\"ordered_volumes\", \"promo_mean_horizon_0\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dea284",
   "metadata": {},
   "source": [
    "Dans ce dataset, on a des données sur le volume des commandes réalisés par les clients, le tout par semaine.\n",
    "On aura le total des commandes effectuées par les clients du Lundi au Vendredi, cette données est disponible dans les colonnes : <br> <b>ordered_volumes</b> ainsi que dans <br> <b>future_ordered_volumes_until_saturday_of_current_week</b>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5bfd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_index</th>\n",
       "      <th>product_index</th>\n",
       "      <th>precipintensity</th>\n",
       "      <th>apparenttemperaturemax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26946</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>60198</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>40.996632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26947</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>60198</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>34.286678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26948</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>60198</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>40.556255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26949</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>60198</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>51.472401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26950</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>60198</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>44.919128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_index  product_index  precipintensity  apparenttemperaturemax\n",
       "26946 2017-01-09          60198         0.002171               40.996632\n",
       "26947 2017-01-16          60198         0.000264               34.286678\n",
       "26948 2017-01-23          60198         0.001450               40.556255\n",
       "26949 2017-01-30          60198         0.003083               51.472401\n",
       "26950 2017-02-06          60198         0.001145               44.919128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values([\"product_index\", \"time_index\"])\\\n",
    "    .head()[[\"time_index\",\"product_index\",\"precipintensity\", \"apparenttemperaturemax\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22429373",
   "metadata": {},
   "source": [
    "Ici, nous avons affichés certains <b>régresseurs</b>, ils permettent de rajouter de l'information sur la timeline actuelle et éventuellement d'expliquer certains changements aperçus sur la colonne du volume de commandes.\n",
    "Le model <b>prophet</b> ira regarder ces variable et pourra en fonction de la corrélation appliquer des corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96fe38f",
   "metadata": {},
   "source": [
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358ca2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale_df(df):\n",
    "    \"\"\"\n",
    "        Allows to transform data with large scale into percent of min-max\n",
    "        from data set\n",
    "\n",
    "        @param : df, dataframe\n",
    "        @return : df, dataframe\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df[\"ordered_volumes\"] = scaler.fit_transform(np.array(df[\"ordered_volumes\"]).reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "def get_df_selected_columns(df,selected_columns):\n",
    "    \"\"\"\n",
    "        Allows to select columns of a dataframe \n",
    "\n",
    "        @param : df, dataframe\n",
    "        @return : df, dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = []\n",
    "    for col in selected_columns:\n",
    "        if selected_columns[col] == 1:\n",
    "            columns.append(col)\n",
    "    \n",
    "    return df[columns]\n",
    "\n",
    "def year_to_date(date_sep):\n",
    "    \"\"\"\n",
    "        Convert year (from int format) to date based on 1 January <year>\n",
    "        \n",
    "        @param : year, int\n",
    "        @return : date, converted year to date\n",
    "    \"\"\"\n",
    "    if type(date_sep) in [float, int]:\n",
    "        date_sep = datetime.strptime(str(date_sep), \"%Y\")\n",
    "\n",
    "    else:\n",
    "        if len(date_sep) == 4:\n",
    "            date_sep = datetime.strptime(str(date_sep), \"%Y\")\n",
    "        else :\n",
    "            date_sep = datetime.strptime(str(date_sep), \"%Y-%m-%d\")\n",
    "    return date_sep\n",
    "    \n",
    "\n",
    "def prepare_df(df,product_id,selected_columns):\n",
    "    \n",
    "    \"\"\"\n",
    "        Processings on df : \n",
    "            - Select wanted product\n",
    "            - Sort from start date time to end\n",
    "            - Distinguish necessary columns from regressors\n",
    "            - Rename columns (df,y) to fit prophet model expectations\n",
    "        \n",
    "        @param : df, dataframe\n",
    "        @return : df (dataframe), regressor (list of regressors column's names)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.query(f'product_index=={product_id}')\n",
    "    df = get_df_selected_columns(df,selected_columns).sort_values('time_index')\n",
    "    updated_columns = set(df.columns)\n",
    "    main_columns = set([\"time_index\", \"ordered_volumes\"])\n",
    "    \n",
    "    regressor = updated_columns.difference(main_columns)\n",
    "    \n",
    "    df= df[df['ordered_volumes']>0]\n",
    "    df.rename(columns = {\"time_index\" : \"ds\", \"ordered_volumes\" : \"y\"}, inplace=True)\n",
    "    df.dropna(subset=regressor, inplace=True)\n",
    "    regressor = list(regressor)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df.dropna(subset=regressor, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df, regressor\n",
    "    \n",
    "def split_df(df, prediction_w_period,separation_date):\n",
    "    \n",
    "    \"\"\"\n",
    "        Used to make train set and test set, takes a separation date\n",
    "        and a prediction period in weeks\n",
    "        \n",
    "        @param : df, dataframe\n",
    "        @param : prediction_w_period, period of prediction in weeks\n",
    "        @param : separation_date, the separation date which takes\n",
    "        the first part for train and second part calculated with prediction_w_period\n",
    "    \"\"\"\n",
    "    \n",
    "    separation_date = year_to_date(separation_date)\n",
    "    \n",
    "    df_train = df[df.ds.apply(lambda date:date)<separation_date]\n",
    "    df_test = df[df.ds.apply(lambda date:date)>=separation_date]\n",
    "    df_test = df_test.iloc[:prediction_w_period]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d082282",
   "metadata": {},
   "source": [
    "# Voir la documentation : <a href = \"https://github.com/ourownstory/neural_prophet/blob/main/neuralprophet/forecaster.py\">NeuralProphet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9526b0c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'danone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchangepoints\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m#lorsqu'on donne ce paramètre, le model ne va detecter aucun changepoints (ce n'est pas le paramètre par défaut)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_changepoints\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m25\u001b[39m, \u001b[38;5;66;03m# nombre de changepoints # pas utile si on spécifie changepoints\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_data_normalization\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m }\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_neural_prophet_model\u001b[39m( params \u001b[38;5;241m=\u001b[39m params,\n\u001b[1;32m---> 33\u001b[0m                                 df \u001b[38;5;241m=\u001b[39m \u001b[43mdanone\u001b[49m,\n\u001b[0;32m     34\u001b[0m                                 freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW-MON\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m                                 product_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70189\u001b[39m,\n\u001b[0;32m     36\u001b[0m                                 date_sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2021\u001b[39m,\n\u001b[0;32m     37\u001b[0m                                 periode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;66;03m# nombre de semaine dans le test_se\u001b[39;00m\n\u001b[0;32m     38\u001b[0m ):\n\u001b[0;32m     40\u001b[0m     selected_columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_index\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered_volumes\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m     42\u001b[0m     df, regressor \u001b[38;5;241m=\u001b[39m prepare_df(df, product_id, selected_columns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'danone' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"changepoints\" : None, #lorsqu'on donne ce paramètre, le model ne va detecter aucun changepoints (ce n'est pas le paramètre par défaut)\n",
    "    \"n_changepoints\" : 25, # nombre de changepoints # pas utile si on spécifie changepoints\n",
    "    \"changepoints_range\" : 0.8, # n_changepoints répartis sur 80% sur train set \n",
    "    \"trend_reg\" : 0,\n",
    "    \"trend_reg_threshold\" : False,\n",
    "    \"yearly_seasonality\" :\"auto\",\n",
    "    \"weekly_seasonality\" :\"auto\",\n",
    "    \"daily_seasonality\": \"auto\",\n",
    "    \"seasonality_mode\" : \"additive\",\n",
    "    \"seasonality_reg\" : 0,\n",
    "    \"n_forecasts\" : 1,\n",
    "    \"n_lags\" : 0,\n",
    "    \"num_hidden_layers\" : 0,\n",
    "    \"d_hidden\" : None,\n",
    "    \"ar_reg\" : None,\n",
    "    \"learning_rate\" : None,\n",
    "    \"epochs\" : None,\n",
    "    \"batch_size\" : None,\n",
    "    \"loss_func\" : \"Huber\",\n",
    "    \"optimizer\" : \"AdamW\",\n",
    "    \"newer_samples_weight\" : 2,\n",
    "    \"newer_samples_start\" : 0.0,\n",
    "    \"impute_missing\" : True,\n",
    "    \"collect_metrics\" :True,\n",
    "    \"normalize\" :\"auto\",\n",
    "    \"global_normalization\" :False,\n",
    "    \"global_time_normalization\" : True,\n",
    "    \"unknown_data_normalization\" : False,\n",
    "}\n",
    "\n",
    "def train_neural_prophet_model( params = params,\n",
    "                                df = danone,\n",
    "                                freq = \"W-MON\",\n",
    "                                product_id = 70189,\n",
    "                                date_sep = 2021,\n",
    "                                periode = 12 # nombre de semaine dans le test_se\n",
    "):\n",
    "    \n",
    "    selected_columns = {\"time_index\" : 1, \"ordered_volumes\" : 1}\n",
    "    \n",
    "    df, regressor = prepare_df(df, product_id, selected_columns)\n",
    "    df_train, df_test = split_df(df,periode,date_sep)\n",
    "    date_sep = year_to_date(date_sep)\n",
    "    \n",
    "            \n",
    "    #if add_holiday == True: \n",
    "    \n",
    "            \n",
    "    m = NeuralProphet(**params)\n",
    "    \n",
    "    m.add_country_holidays(\"FR\")\n",
    "    \n",
    "    df_train, df_val = NeuralProphet().split_df(df_train, valid_p=0.2)\n",
    "    \n",
    "    m.fit(df_train, freq = freq, validation_df = df_val)\n",
    "    \n",
    "    forecast = m.predict(df_test)\n",
    "    \n",
    "    metrics = m.test(df_test)\n",
    "    \n",
    "    future = df_test\n",
    "    \n",
    "    df = pd.concat([df_train, df_val],axis=0)\n",
    "    \n",
    "    df = pd.concat([df, df_test], axis=0)\n",
    "    \n",
    "    residuals = pd.DataFrame()\n",
    "    \n",
    "    residuals['ds']=df[df.ds>=date_sep][\"ds\"]\n",
    "\n",
    "    residuals['e'] = df[df.ds>=date_sep]['y']-forecast[forecast.ds>=date_sep]['yhat1']\n",
    "\n",
    "    residuals.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return m, df, future, forecast, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfde795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_prophet_model(df = danone,\n",
    "                product_id = 70189,\n",
    "\n",
    "                interval = 0.95,\n",
    "\n",
    "                add_holiday = True,\n",
    "\n",
    "                regressor = [],\n",
    "                \n",
    "                #changepoints \n",
    "\n",
    "                changepoints = None, #lorsqu'on donne ce paramètre, le model ne va detecter aucun changepoints (ce n'est pas le paramètre par défaut)\n",
    "\n",
    "                changepoint_prior_scale=0.05, #sensibilité aux changement dans la trend (si on estime par exemple que le changement de trend n'en est pas un)\n",
    "\n",
    "                n_changepoints = 25, # nombre de changepoints # pas utile si on spécifie changepoints\n",
    "\n",
    "                changepoint_range = 0.8, # n_changepoints répartis sur 80% sur train set \n",
    "\n",
    "                #growth\n",
    "\n",
    "                growth = 'linear', #type de trend 'linear', 'logistic' or 'flat' \n",
    "                                     #si growth = logistic on est obligé de renseigné cap \n",
    "\n",
    "                cap = None, # default = None# carrying capacity : When forecasting growth, there is usually some maximum achievable point: total market size = carrying capacity\n",
    "                        #cap peut être une liste comme une constante\n",
    "\n",
    "                floor = None,\n",
    "\n",
    "                holidays = pd.DataFrame({'ds':pd.to_datetime(['2017-01-16']),\n",
    "                                         'holiday':'saint-machin'}), #default = None\n",
    "\n",
    "                #saisonnalité \n",
    "\n",
    "                #on peut donner la valeur False lorsqu'on vetu disabler une forme de saisonnalité\n",
    "\n",
    "                yearly_seasonality = 'auto', # un entier sinon \n",
    "                                          #The default values are often appropriate, but they can be increased when the seasonality needs to fit higher-frequency changes, and generally be less smooth\n",
    "                                          # tester 'auto' et 10 qui est selon la doc la valeur par défaut\n",
    "                                          #Increasing the number of Fourier terms allows the seasonality to fit faster changing cycles, but can also lead to overfitting: N Fourier terms corresponds to 2N variables used for modeling the cycle\n",
    "                                          # https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html#specifying-custom-seasonalities\n",
    "                                                          # on peut ajouté seasonality_prior_scale \n",
    "\n",
    "                seasonality_mode = 'additive', #ou mutliplicative\n",
    "\n",
    "                # si les vacances ou les saisonnalités sont overfittés ou peut utiliser prior scale (defaut =10)\n",
    "\n",
    "                seasonality_prior_scale = 10.0,\n",
    "                holidays_prior_scale = 10.0,\n",
    "\n",
    "                mcmc_samples = 0,\n",
    "\n",
    "                uncertainty_samples = 1000,\n",
    "                \n",
    "                date_sep = 2021,\n",
    "\n",
    "                periode = 12 # nombre de semaine dans le test_set\n",
    "):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Process the danone df, split it, train the model on the train. \n",
    "\n",
    "    Return the trained model, the processed prophet friendly df, the forecast df with forecasted values and the residuals df with residuals.\n",
    "        \n",
    "    @param df, DataFrame (default=danone)\n",
    "    \n",
    "    @param product_id, int : the produt_index we want to forecast, must be in the 'product_index' column of df\n",
    "    \n",
    "    @param date_sep int or string : the date at which we want to divide our dataset. \n",
    "    example : '2019', 2019, '2020-01-13'\n",
    "    \n",
    "    @param periode, int : number of weeks we want in the train set \n",
    "    \n",
    "    @param cap : int, DataFrame, Series, array, list : carrying capacity : When forecasting growth, there is usually some maximum achievable point: total market size, total population size, etc. This is called the carrying capacity, and the forecast should saturate at this point. \n",
    "    \n",
    "    @param floor : int, DataFrame, Series, array, list saturating minimum\n",
    "    \n",
    "    @param interval : Float, width of the uncertainty intervals provided for the forecast.\n",
    "    If mcmc_samples=0, this will be only the uncertainty in the trend using the MAP estimate of the extrapolated generative model.\n",
    "    If mcmc.samples>0, this will be integrated over all model parameters, which will include uncertainty in seasonality. \n",
    "    \n",
    "    @param add_holidays, bool : True if we want to include the effects of prophet built-in holidays (defalut=False)\n",
    "    (Jour de l'an, Fête du Travail, Armistice 1945, Fête nationale, Armistice 1918, Lundi de Pâques, Lundi de Pentecôte, Ascension, Assomption, Toussaint, Noël)\n",
    "    \n",
    "    @param regressor, list : list of the regressors we want to include in the model, must be names of columns of df. (default=empty list)\n",
    "    \n",
    "    @param changepoints, list : list of dates where we suspect a change in the trend, dates must be strings and must be in the time_index column of df (default=None)\n",
    "    \n",
    "    @param n_changepoints, int : if changepoints=None, the model distribute n_changepoints on the train_set and test if there is a change in the trend at those points.\n",
    "    Not used if `changepoints` is specified\n",
    "    \n",
    "    @param changepoint_range, float in [0,1] : Proportion of history in which trend changepoints willbe estimated.\n",
    "    Defaults to 0.8 for the first 80%. Not used if`changepoints` is specified\n",
    "    \n",
    "    @param yearly_seasonality : 'auto', True, False or a number of Fourier terms to generate (default=auto)\n",
    "    \n",
    "    \n",
    "    @param holidays : DataFrame with columns holiday (string) and ds (date type)\n",
    "    and optionally columns lower_window and upper_window which specify arange of days around the date to be included as holidays.lower_window=-2 will include 2 days prior to the date as holidays.\n",
    "    Also optionally can have a column prior_scale specifying the prior scale for that holiday.\n",
    "    \n",
    "    @param seasonality_mode : 'additive'(default), 'mutltiplicative'\n",
    "    \n",
    "    @param seasonality_prior_scale : int or float, Parameter modulating the strength of the seasonality model.\n",
    "    Larger values allow the model to fit larger seasonal fluctuations, smaller values dampen the seasonality. Can be specified for individual seasonalities using add_seasonality.\n",
    "    \n",
    "    @param holidays_prior_scale : int or float, Parameter modulating the strength of the holiday components model, unless overridden in the holidays input.\n",
    "    \n",
    "    @param mcmc_samples : int, if greater than 0, will do full Bayesian inference with the specified number of MCMC samples. If 0, will do MAP estimation.\n",
    "    \n",
    "    @param uncertainty_samples : Number of simulated draws used to estimate uncertainty intervals. Settings this value to 0 or False will disable uncertainty estimation and speed up the calculation. \n",
    "    \n",
    "    @return m : prophet model : the trained model\n",
    "    \n",
    "    @return df : DataFrame : the processed df in a prophet-friendly shape \n",
    "    \n",
    "    @return future : DataFrame : a single column DataFrame with train set dates and test set dates concatenated\n",
    "    \n",
    "    @return residuals : DataFrame : DataFrame : DataFrame with e = y-yhat for each prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.query(f'product_index=={product_id}')\n",
    "    df = df[['time_index','ordered_volumes']+regressor].sort_values('time_index')\n",
    "    df = df[df['ordered_volumes']>0]\n",
    "    df.columns = ['ds','y']+regressor\n",
    "    df.dropna(subset=regressor, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "    if cap !=None and growth == 'linear':\n",
    "        df['cap'] = cap ####################### future a remplacer \n",
    "        df['floor'] = floor\n",
    "\n",
    "    if floor !=None and growth == 'logistic':\n",
    "        df['cap'] = cap \n",
    "        df['floor'] = floor  #####################\n",
    "\n",
    "    df.dropna(subset=regressor, inplace=True)\n",
    "\n",
    "\n",
    "    if type(date_sep) in [float, int]:\n",
    "        date_sep = datetime.strptime(str(date_sep), \"%Y\")\n",
    "        df_train = df[df.ds<date_sep]\n",
    "        df_test = df[df.ds>=date_sep]\n",
    "\n",
    "    else:\n",
    "        if len(date_sep) == 4:\n",
    "            date_sep = datetime.strptime(str(date_sep), \"%Y\")\n",
    "            df_train = df[df.ds<date_sep]\n",
    "            df_test = df[df.ds>=date_sep]\n",
    "        else :\n",
    "            date_sep = datetime.strptime(str(date_sep), \"%Y-%m-%d\")\n",
    "            df_train = df[df.ds<date_sep]\n",
    "            df_test = df[df.ds>=date_sep]\n",
    "\n",
    "    m = Prophet(interval_width=interval, changepoints=changepoints, changepoint_prior_scale=changepoint_prior_scale,n_changepoints=n_changepoints,\n",
    "                growth=growth,\n",
    "                holidays=holidays, holidays_prior_scale=holidays_prior_scale,\n",
    "                yearly_seasonality=yearly_seasonality,\n",
    "                #weekly_seasonality=weekly_seasonality, daily_seasonality=daily_seasonality,\n",
    "                seasonality_prior_scale=seasonality_prior_scale,\n",
    "                mcmc_samples=mcmc_samples, uncertainty_samples=uncertainty_samples)\n",
    "\n",
    "    if add_holiday == True: \n",
    "        m.add_country_holidays(country_name=\"FR\")\n",
    "\n",
    "    for reg in regressor:\n",
    "        m.add_regressor(regressor)\n",
    "\n",
    "    m.fit(df_train)\n",
    "\n",
    "    future = m.make_future_dataframe(periods=len(df_test), freq='W-MON', include_history=True)\n",
    "\n",
    "    future[regressor] = df[regressor] # à modifier si include_history=False\n",
    "\n",
    "    if cap !=None and growth == 'linear':\n",
    "        future['cap'] = cap  \n",
    "\n",
    "    if floor !=None and growth == 'logistic':\n",
    "        future['cap'] = cap \n",
    "        future['floor'] = floor \n",
    "\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    residuals = pd.DataFrame()\n",
    "    \n",
    "    df = pd.concat([df_train,df_test], axis = 0)\n",
    "\n",
    "    residuals['ds']=future.tail(periode)[\"ds\"]\n",
    "\n",
    "    residuals['e'] = df[df.ds>=date_sep]['y']-forecast[forecast.ds>=date_sep]['yhat']\n",
    "\n",
    "    residuals.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return m, df, future, forecast, residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aba555",
   "metadata": {},
   "source": [
    "# Affichage des performances du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af55623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_my_ploty_graph(df, forecast, product_id=70189,year=2021):\n",
    "    mse = mean_squared_error(forecast['yhat'],df['y']) ######### a modifier\n",
    "    mae = mean_absolute_error(forecast['yhat'],df['y'])\n",
    "\n",
    "    s1 = go.Scatter(x=forecast['ds'], y=forecast['yhat_lower'], name='yhat_lower',fill='tonexty',line={\"color\":\"gray\"},fillcolor='rgba(68, 68, 68, 0.1)',showlegend=True)\n",
    "\n",
    "    s2 = go.Scatter(x=forecast['ds'], y=forecast['yhat'], name='prediction',line={\"color\":\"red\"})\n",
    "\n",
    "    s3 = go.Scatter(x=forecast['ds'], y=forecast['yhat_upper'], name='yhat_upper',line={\"color\":\"gray\"},showlegend=True)\n",
    "\n",
    "    fig = go.Figure(data=[s2,s3,s1],layout={'title':f'Prédiction à 1 an des quantités de {product_id}'})\n",
    "\n",
    "    fig.add_scatter(x=df['ds'],y=df['y'],mode='markers',name='Quantité observée')\n",
    "\n",
    "    fig.add_vline(x=str(year_to_date(year)), line_width=3, line_color=\"green\")\n",
    "\n",
    "    fig.add_annotation(x='2017', y=600,\n",
    "                text=f\"MSE : {mse}\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1)\n",
    "\n",
    "    fig.add_annotation(x='2017', y=550,\n",
    "                text=f\"MAE : {mae}\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1)\n",
    "\n",
    "\n",
    "    fig.update_layout(hovermode='x',\n",
    "                     xaxis_title='Date',yaxis_title='Quantités')\n",
    "\n",
    "    #fig.show()\n",
    "    \n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14798314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_my_neural_graph(forecasts, product_id=70189,year=2021):\n",
    "    \"\"\"\n",
    "    Show model's benchmarks via graphical interface\n",
    "    \n",
    "    @param : forecast, dataframe with ds, y and yhat (prediction value)\n",
    "    @param : product_id, the product id to select\n",
    "    @param : year, the separation year between train and test set\n",
    "    \"\"\"\n",
    "        \n",
    "    #mse = mean_squared_error(forecast['yhat1'],forecast['y']) ######### a modifier\n",
    "    #mae = mean_absolute_error(forecast['yhat1'],forecast['y'])\n",
    "    \n",
    "    #s1 = go.Scatter(x=forecast['ds'], y=forecast['yhat1'], name='prediction',line={\"color\":\"green\"})\n",
    "    \n",
    "    dat = []\n",
    "    \n",
    "    for forecast in forecasts :\n",
    "        rd = random.randint(0,16777215)\n",
    "        hex_number = str(hex(rd))\n",
    "        hex_color ='#'+ hex_number[2:]\n",
    "        dat.append(go.Scatter(x=forecast['ds'], y=forecast['yhat1'], name='prediction',line={\"color\":hex_color}))\n",
    "    \n",
    "\n",
    "        \n",
    "    fig = go.Figure(data=dat,layout={'title':f'Prédiction à 1 an des quantités de {product_id}'})\n",
    "    \n",
    "    for forecast in forecasts :\n",
    "        fig.add_scatter(x=forecast['ds'],y=forecast['y'],mode='markers',name='Quantité observée')\n",
    "        '''fig.add_annotation(x='2017', y=600,\n",
    "                text=f\"MSE : {mean_squared_error(forecast['yhat1'],forecast['y'])}\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1)\n",
    "        fig.add_annotation(x='2017', y=550,\n",
    "                text=f\"MAE : {mean_absolute_error(forecast['yhat1'],forecast['y'])}\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1)'''\n",
    "        \n",
    "\n",
    "    #fig.add_vline(x=str(year_to_date(year)), line_width=3, line_color=\"green\")\n",
    "\n",
    "\n",
    "    '''fig.add_annotation(x='2017', y=600,\n",
    "                text=f\"MSE : {mse}\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1)\n",
    "\n",
    "    fig.add_annotation(x='2017', y=550,\n",
    "                text=f\"MAE : {mae}\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1)'''\n",
    "\n",
    "    fig.update_layout(hovermode='x',\n",
    "                     xaxis_title='Date',yaxis_title='Quantités')\n",
    "\n",
    "    #fig.show()\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b82a67",
   "metadata": {},
   "source": [
    "# Entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0323f24c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "WARNING - (py.warnings._showwarnmsg) - D:\\Users\\amiar\\anaconda3\\lib\\site-packages\\prophet\\forecaster.py:896: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "\n",
      "WARNING:py.warnings:D:\\Users\\amiar\\anaconda3\\lib\\site-packages\\prophet\\forecaster.py:896: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - D:\\Users\\amiar\\anaconda3\\lib\\site-packages\\prophet\\forecaster.py:896: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "\n",
      "WARNING:py.warnings:D:\\Users\\amiar\\anaconda3\\lib\\site-packages\\prophet\\forecaster.py:896: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - D:\\Users\\amiar\\anaconda3\\lib\\site-packages\\prophet\\forecaster.py:896: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "\n",
      "WARNING:py.warnings:D:\\Users\\amiar\\anaconda3\\lib\\site-packages\\prophet\\forecaster.py:896: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#m, danone, future, forecast, residuals, metrics = train_neural_prophet_model(params)\n",
    "#m, danone, future, forecast, residuals = train_prophet_model(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
